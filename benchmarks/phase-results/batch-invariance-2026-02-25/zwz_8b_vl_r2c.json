{
  "model": "swaylenhayes/ZwZ-8B-VL-MLX-4bit",
  "base_url": "http://localhost:8000",
  "prompt_count": 10,
  "max_tokens": 32,
  "concurrency": 2,
  "runs": 5,
  "confidence_level": 0.95,
  "exact_match_rate": 0.34,
  "token_agreement_rate": 0.6865122902513094,
  "exact_match_summary": {
    "mean": 0.34,
    "stdev": 0.05477225575051663,
    "ci_lower": 0.29199000104144973,
    "ci_upper": 0.3880099989585503
  },
  "token_agreement_summary": {
    "mean": 0.6865122902513094,
    "stdev": 0.032345992589366025,
    "ci_lower": 0.658159777665335,
    "ci_upper": 0.7148648028372839
  },
  "rows": [
    {
      "index": 0,
      "prompt": "Write one sentence explaining why caching helps inference throughput.",
      "serial_output": "Caching helps inference throughput by reducing redundant computation and data retrieval, allowing faster access to previously computed results or frequently used model parameters.",
      "concurrent_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to serve repeated or similar requests faster.",
      "token_agreement": 0.4783,
      "exact_match": false,
      "serial_latency_s": 0.6474,
      "concurrent_latency_s": 0.8332
    },
    {
      "index": 1,
      "prompt": "List three steps to verify an API endpoint is healthy.",
      "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (GET /health or similar endpoint)**  \n   Many APIs",
      "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request**  \n   Make a GET request (often to `/health",
      "token_agreement": 0.6667,
      "exact_match": false,
      "serial_latency_s": 0.7245,
      "concurrent_latency_s": 0.875
    },
    {
      "index": 2,
      "prompt": "What is the capital of France? Answer in one word.",
      "serial_output": "Paris",
      "concurrent_output": "Paris",
      "token_agreement": 1.0,
      "exact_match": true,
      "serial_latency_s": 0.1365,
      "concurrent_latency_s": 0.2691
    },
    {
      "index": 3,
      "prompt": "Return exactly: ping",
      "serial_output": "ping",
      "concurrent_output": "ping",
      "token_agreement": 1.0,
      "exact_match": true,
      "serial_latency_s": 0.1333,
      "concurrent_latency_s": 0.2272
    },
    {
      "index": 4,
      "prompt": "Name two risks of running without authentication.",
      "serial_output": "Running without authentication exposes systems and data to several security threats. Two major risks include:\n\n1. **Unauthorized Access**: Anyone with network or system access (including malicious",
      "concurrent_output": "Running without authentication poses significant security risks. Here are two major risks:\n\n1. **Unauthorized Access** \u2013 Anyone with access to the system or network can log in",
      "token_agreement": 0.1111,
      "exact_match": false,
      "serial_latency_s": 0.7099,
      "concurrent_latency_s": 0.876
    },
    {
      "index": 5,
      "prompt": "Summarize why deterministic decoding matters in testing.",
      "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, repeatable, and reliable behavior** in systems that rely on decoding \u2014 such as neural networks,",
      "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** \u2014 which is essential for reliable validation and debugging. Here\u2019s",
      "token_agreement": 0.4583,
      "exact_match": false,
      "serial_latency_s": 0.7311,
      "concurrent_latency_s": 0.8757
    },
    {
      "index": 6,
      "prompt": "What does a 503 status code usually indicate?",
      "serial_output": "A **503 Service Unavailable** status code usually indicates that the server is **temporarily unable to handle the request**, often due to **overload",
      "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **temporarily unable to handle the request**, often due to:\n\n- **",
      "token_agreement": 0.8696,
      "exact_match": false,
      "serial_latency_s": 0.7171,
      "concurrent_latency_s": 0.8852
    },
    {
      "index": 7,
      "prompt": "Give a one-line definition of batch invariance.",
      "serial_output": "Batch invariance is the property of a model or algorithm whose output remains consistent regardless of the batch size used during training or inference.",
      "concurrent_output": "Batch invariance is the property of a model or system that produces consistent outputs regardless of the batch size used during inference or training.",
      "token_agreement": 0.7083,
      "exact_match": false,
      "serial_latency_s": 0.6392,
      "concurrent_latency_s": 0.8842
    },
    {
      "index": 8,
      "prompt": "Provide two bullet points on memory pressure guardrails.",
      "serial_output": "- Monitor and limit memory usage per container or process to prevent system-wide instability, using tools like cgroups or memory limits in orchestration platforms (e.g.,",
      "concurrent_output": "- Monitor and limit memory usage per container or pod to prevent resource contention and system instability, especially in multi-tenant environments.\n\n- Implement memory throttling and eviction",
      "token_agreement": 0.4074,
      "exact_match": false,
      "serial_latency_s": 0.7195,
      "concurrent_latency_s": 0.8285
    },
    {
      "index": 9,
      "prompt": "Output the word READY and nothing else.",
      "serial_output": "READY",
      "concurrent_output": "READY",
      "token_agreement": 1.0,
      "exact_match": true,
      "serial_latency_s": 0.1335,
      "concurrent_latency_s": 0.3361
    }
  ],
  "run_reports": [
    {
      "run_index": 0,
      "exact_match_rate": 0.3,
      "token_agreement_rate": 0.6851630564645993,
      "rows": [
        {
          "index": 0,
          "prompt": "Write one sentence explaining why caching helps inference throughput.",
          "serial_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to serve repeated or similar requests faster.",
          "concurrent_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing frequently requested inputs or model states to be retrieved quickly without reprocessing.",
          "token_agreement": 0.5,
          "exact_match": false,
          "serial_latency_s": 1.3039,
          "concurrent_latency_s": 0.9069
        },
        {
          "index": 1,
          "prompt": "List three steps to verify an API endpoint is healthy.",
          "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (GET /health or similar)**  \n   Many APIs expose",
          "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Request and Check HTTP Status Code**  \n   Make a simple request (e",
          "token_agreement": 0.56,
          "exact_match": false,
          "serial_latency_s": 0.698,
          "concurrent_latency_s": 0.9073
        },
        {
          "index": 2,
          "prompt": "What is the capital of France? Answer in one word.",
          "serial_output": "Paris",
          "concurrent_output": "Paris",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1351,
          "concurrent_latency_s": 0.2262
        },
        {
          "index": 3,
          "prompt": "Return exactly: ping",
          "serial_output": "ping",
          "concurrent_output": "ping",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1323,
          "concurrent_latency_s": 0.2258
        },
        {
          "index": 4,
          "prompt": "Name two risks of running without authentication.",
          "serial_output": "Running without authentication exposes systems to several security risks. Two major risks include:\n\n1. **Unauthorized Access**: Anyone with network or system access (including malicious actors)",
          "concurrent_output": "Running without authentication introduces significant security and operational risks. Here are two key risks:\n\n1. **Unauthorized Access**: Anyone with network access (including malicious actors) can",
          "token_agreement": 0.16,
          "exact_match": false,
          "serial_latency_s": 0.7044,
          "concurrent_latency_s": 0.8708
        },
        {
          "index": 5,
          "prompt": "Summarize why deterministic decoding matters in testing.",
          "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, repeatable, and reliable behavior** of the system under test \u2014 especially in systems involving natural language",
          "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, repeatable, and reliable behavior** \u2014 crucial for accurate validation and debugging.\n\nHere\u2019s why:",
          "token_agreement": 0.52,
          "exact_match": false,
          "serial_latency_s": 0.7313,
          "concurrent_latency_s": 0.8705
        },
        {
          "index": 6,
          "prompt": "What does a 503 status code usually indicate?",
          "serial_output": "A **503 Service Unavailable** status code usually indicates that the server is **temporarily unable to handle the request**, often due to **overload",
          "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, typically due to **temporary overloading",
          "token_agreement": 0.8261,
          "exact_match": false,
          "serial_latency_s": 0.7185,
          "concurrent_latency_s": 0.8882
        },
        {
          "index": 7,
          "prompt": "Give a one-line definition of batch invariance.",
          "serial_output": "Batch invariance is the property of a model or algorithm producing consistent outputs regardless of how its input data is partitioned into batches during training or inference.",
          "concurrent_output": "Batch invariance is the property of a model or algorithm producing consistent outputs regardless of how the input data is partitioned into batches during training or inference.",
          "token_agreement": 0.963,
          "exact_match": false,
          "serial_latency_s": 0.7143,
          "concurrent_latency_s": 0.8878
        },
        {
          "index": 8,
          "prompt": "Provide two bullet points on memory pressure guardrails.",
          "serial_output": "- Monitor and limit memory usage per process or container to prevent system-wide slowdowns or crashes due to memory exhaustion.\n\n- Implement automatic memory throttling or eviction policies",
          "concurrent_output": "- Monitor and limit memory usage per container or pod to prevent resource exhaustion and ensure system stability under memory pressure.\n\n- Implement automatic eviction policies and memory thresholds to gracefully",
          "token_agreement": 0.3226,
          "exact_match": false,
          "serial_latency_s": 0.6971,
          "concurrent_latency_s": 0.8197
        },
        {
          "index": 9,
          "prompt": "Output the word READY and nothing else.",
          "serial_output": "READY",
          "concurrent_output": "READY",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1345,
          "concurrent_latency_s": 0.3303
        }
      ]
    },
    {
      "run_index": 1,
      "exact_match_rate": 0.4,
      "token_agreement_rate": 0.7088803376089733,
      "rows": [
        {
          "index": 0,
          "prompt": "Write one sentence explaining why caching helps inference throughput.",
          "serial_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to serve repeated or similar inputs faster.",
          "concurrent_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to quickly retrieve previously computed results or weights instead of reprocessing the same inputs or",
          "token_agreement": 0.5172,
          "exact_match": false,
          "serial_latency_s": 0.6332,
          "concurrent_latency_s": 0.8695
        },
        {
          "index": 1,
          "prompt": "List three steps to verify an API endpoint is healthy.",
          "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request**  \n   Make a GET request (or use the endpoint",
          "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (e.g., GET /health or /status)**",
          "token_agreement": 0.64,
          "exact_match": false,
          "serial_latency_s": 0.7046,
          "concurrent_latency_s": 0.8695
        },
        {
          "index": 2,
          "prompt": "What is the capital of France? Answer in one word.",
          "serial_output": "Paris",
          "concurrent_output": "Paris",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1364,
          "concurrent_latency_s": 0.2269
        },
        {
          "index": 3,
          "prompt": "Return exactly: ping",
          "serial_output": "ping",
          "concurrent_output": "ping",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1315,
          "concurrent_latency_s": 0.2266
        },
        {
          "index": 4,
          "prompt": "Name two risks of running without authentication.",
          "serial_output": "Running without authentication introduces significant security and operational risks. Here are two key risks:\n\n1. **Unauthorized Access**: Anyone with access to the system \u2014 including malicious actors",
          "concurrent_output": "Running without authentication exposes systems to several security risks. Two major risks are:\n\n1. **Unauthorized Access**: Anyone, including malicious actors, can access sensitive resources,",
          "token_agreement": 0.1481,
          "exact_match": false,
          "serial_latency_s": 0.7058,
          "concurrent_latency_s": 0.8942
        },
        {
          "index": 5,
          "prompt": "Summarize why deterministic decoding matters in testing.",
          "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and repeatable behavior** of the system under test \u2014 especially in scenarios involving **language",
          "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** \u2014 which is critical for reliable validation and debugging.\n\nHere\u2019s",
          "token_agreement": 0.5,
          "exact_match": false,
          "serial_latency_s": 0.7285,
          "concurrent_latency_s": 0.8939
        },
        {
          "index": 6,
          "prompt": "What does a 503 status code usually indicate?",
          "serial_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, often due to **temporary overload,",
          "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, typically due to **temporary overloading",
          "token_agreement": 0.913,
          "exact_match": false,
          "serial_latency_s": 0.7163,
          "concurrent_latency_s": 0.8957
        },
        {
          "index": 7,
          "prompt": "Give a one-line definition of batch invariance.",
          "serial_output": "Batch invariance means a model\u2019s output remains consistent regardless of how its input data is partitioned into batches during training or inference.",
          "concurrent_output": "Batch invariance means a model\u2019s output remains consistent regardless of how its input data is partitioned into batches during training or inference.",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.6332,
          "concurrent_latency_s": 0.8948
        },
        {
          "index": 8,
          "prompt": "Provide two bullet points on memory pressure guardrails.",
          "serial_output": "- Monitor and limit memory usage per process or container to prevent system-wide instability, using tools like cgroups or memory limits in orchestration platforms.\n\n- Implement graceful",
          "concurrent_output": "- Monitor and limit memory usage per container or pod to prevent resource contention and system instability, using mechanisms like Kubernetes\u2019 `resources.limits` or Docker\u2019s `",
          "token_agreement": 0.3704,
          "exact_match": false,
          "serial_latency_s": 0.719,
          "concurrent_latency_s": 0.8218
        },
        {
          "index": 9,
          "prompt": "Output the word READY and nothing else.",
          "serial_output": "READY",
          "concurrent_output": "READY",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1355,
          "concurrent_latency_s": 0.3338
        }
      ]
    },
    {
      "run_index": 2,
      "exact_match_rate": 0.4,
      "token_agreement_rate": 0.6430490910056127,
      "rows": [
        {
          "index": 0,
          "prompt": "Write one sentence explaining why caching helps inference throughput.",
          "serial_output": "Caching helps inference throughput by reducing redundant computation and data fetches, allowing faster access to previously processed inputs or precomputed results.",
          "concurrent_output": "Caching helps inference throughput by reducing redundant computation and data loading, allowing the model to respond faster to repeated or similar queries.",
          "token_agreement": 0.5455,
          "exact_match": false,
          "serial_latency_s": 0.6476,
          "concurrent_latency_s": 0.8518
        },
        {
          "index": 1,
          "prompt": "List three steps to verify an API endpoint is healthy.",
          "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (e.g., GET /health or /status)**",
          "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request**  \n   - Make a simple GET request (often to",
          "token_agreement": 0.64,
          "exact_match": false,
          "serial_latency_s": 0.7202,
          "concurrent_latency_s": 0.875
        },
        {
          "index": 2,
          "prompt": "What is the capital of France? Answer in one word.",
          "serial_output": "Paris",
          "concurrent_output": "Paris",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1382,
          "concurrent_latency_s": 0.2486
        },
        {
          "index": 3,
          "prompt": "Return exactly: ping",
          "serial_output": "ping",
          "concurrent_output": "ping",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1355,
          "concurrent_latency_s": 0.2255
        },
        {
          "index": 4,
          "prompt": "Name two risks of running without authentication.",
          "serial_output": "Running without authentication introduces significant security and operational risks. Here are two major risks:\n\n1. **Unauthorized Access**: Anyone with access to the system \u2014 including malicious actors",
          "concurrent_output": "Running without authentication exposes systems to several security risks. Two major risks are:\n\n1. **Unauthorized Access** \u2013 Anyone with network or system access (including malicious actors",
          "token_agreement": 0.2222,
          "exact_match": false,
          "serial_latency_s": 0.7206,
          "concurrent_latency_s": 0.8689
        },
        {
          "index": 5,
          "prompt": "Summarize why deterministic decoding matters in testing.",
          "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** \u2014 which is essential for reliable validation and debugging.\n\nHere\u2019s",
          "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** \u2014 which is essential for reliable validation and debugging.\n\nHere\u2019s",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.7204,
          "concurrent_latency_s": 0.8686
        },
        {
          "index": 6,
          "prompt": "What does a 503 status code usually indicate?",
          "serial_output": "A **503 Service Unavailable** HTTP status code usually indicates that the server is **temporarily unable to handle the request**, often due to **over",
          "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, typically due to **temporary overloads",
          "token_agreement": 0.1739,
          "exact_match": false,
          "serial_latency_s": 0.7211,
          "concurrent_latency_s": 0.8862
        },
        {
          "index": 7,
          "prompt": "Give a one-line definition of batch invariance.",
          "serial_output": "Batch invariance is the property of a model or system where its output remains consistent regardless of how input data is partitioned into batches during processing.",
          "concurrent_output": "Batch invariance is the property of a model or system producing consistent outputs regardless of how its inputs are grouped into batches during processing.",
          "token_agreement": 0.3846,
          "exact_match": false,
          "serial_latency_s": 0.6997,
          "concurrent_latency_s": 0.885
        },
        {
          "index": 8,
          "prompt": "Provide two bullet points on memory pressure guardrails.",
          "serial_output": "- Monitor and limit memory usage per container or process to prevent system-wide slowdowns or crashes due to memory exhaustion.\n\n- Implement automatic memory throttling or kill signals",
          "concurrent_output": "- Monitor and limit memory usage per container or process to prevent system-wide memory exhaustion and ensure service stability.\n\n- Implement automatic scaling or graceful degradation (e.g.,",
          "token_agreement": 0.4643,
          "exact_match": false,
          "serial_latency_s": 0.7243,
          "concurrent_latency_s": 0.8165
        },
        {
          "index": 9,
          "prompt": "Output the word READY and nothing else.",
          "serial_output": "READY",
          "concurrent_output": "READY",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1341,
          "concurrent_latency_s": 0.3314
        }
      ]
    },
    {
      "run_index": 3,
      "exact_match_rate": 0.3,
      "token_agreement_rate": 0.7255011722965246,
      "rows": [
        {
          "index": 0,
          "prompt": "Write one sentence explaining why caching helps inference throughput.",
          "serial_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to serve repeated or similar inputs faster without reprocessing.",
          "concurrent_output": "Caching helps inference throughput by reducing redundant computation and data loading, allowing the model to serve subsequent requests faster by reusing previously computed or loaded results.",
          "token_agreement": 0.5385,
          "exact_match": false,
          "serial_latency_s": 0.6767,
          "concurrent_latency_s": 0.9371
        },
        {
          "index": 1,
          "prompt": "List three steps to verify an API endpoint is healthy.",
          "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (e.g., GET /health or /status)**",
          "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (e.g., GET /health)**  \n   Many APIs",
          "token_agreement": 0.8636,
          "exact_match": false,
          "serial_latency_s": 0.7222,
          "concurrent_latency_s": 0.937
        },
        {
          "index": 2,
          "prompt": "What is the capital of France? Answer in one word.",
          "serial_output": "Paris",
          "concurrent_output": "Paris",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1395,
          "concurrent_latency_s": 0.2248
        },
        {
          "index": 3,
          "prompt": "Return exactly: ping",
          "serial_output": "ping",
          "concurrent_output": "ping",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1339,
          "concurrent_latency_s": 0.2251
        },
        {
          "index": 4,
          "prompt": "Name two risks of running without authentication.",
          "serial_output": "Running without authentication introduces significant security and operational risks. Here are two key risks:\n\n1. **Unauthorized Access**: Anyone with access to the system or network can interact",
          "concurrent_output": "Running without authentication introduces significant security and operational risks. Two major risks are:\n\n1. **Unauthorized Access**: Anyone with access to the system or service can interact with",
          "token_agreement": 0.3333,
          "exact_match": false,
          "serial_latency_s": 0.7087,
          "concurrent_latency_s": 0.8992
        },
        {
          "index": 5,
          "prompt": "Summarize why deterministic decoding matters in testing.",
          "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** of the system under test \u2014 especially when decoding encoded data,",
          "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, repeatable, and reliable behavior** \u2014 which is essential for valid test results. Here\u2019s why",
          "token_agreement": 0.4583,
          "exact_match": false,
          "serial_latency_s": 0.7166,
          "concurrent_latency_s": 0.899
        },
        {
          "index": 6,
          "prompt": "What does a 503 status code usually indicate?",
          "serial_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, often due to **temporary overloading",
          "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **currently unable to handle the request**, typically due to **temporary overloading",
          "token_agreement": 0.9565,
          "exact_match": false,
          "serial_latency_s": 0.714,
          "concurrent_latency_s": 0.8889
        },
        {
          "index": 7,
          "prompt": "Give a one-line definition of batch invariance.",
          "serial_output": "Batch invariance is the property of a model or system producing consistent outputs regardless of the batch size used during inference or training.",
          "concurrent_output": "Batch invariance is the property of a model or algorithm producing consistent outputs regardless of how its input data is partitioned into batches during training or inference.",
          "token_agreement": 0.5185,
          "exact_match": false,
          "serial_latency_s": 0.6393,
          "concurrent_latency_s": 0.8887
        },
        {
          "index": 8,
          "prompt": "Provide two bullet points on memory pressure guardrails.",
          "serial_output": "- Monitor and limit memory usage per container or process to prevent system-wide memory exhaustion and ensure stable performance under high load.\n\n- Implement automatic scaling or memory throttling",
          "concurrent_output": "- Monitor and limit memory usage per container or pod to prevent system-wide memory exhaustion and ensure resource fairness across workloads.\n\n- Implement automatic memory throttling or O",
          "token_agreement": 0.5862,
          "exact_match": false,
          "serial_latency_s": 0.7233,
          "concurrent_latency_s": 0.8281
        },
        {
          "index": 9,
          "prompt": "Output the word READY and nothing else.",
          "serial_output": "READY",
          "concurrent_output": "READY",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.137,
          "concurrent_latency_s": 0.3334
        }
      ]
    },
    {
      "run_index": 4,
      "exact_match_rate": 0.3,
      "token_agreement_rate": 0.6699677938808374,
      "rows": [
        {
          "index": 0,
          "prompt": "Write one sentence explaining why caching helps inference throughput.",
          "serial_output": "Caching helps inference throughput by reducing redundant computation and data retrieval, allowing faster access to previously computed results or frequently used model parameters.",
          "concurrent_output": "Caching helps inference throughput by reducing redundant computation and memory access, allowing the model to serve repeated or similar requests faster.",
          "token_agreement": 0.4783,
          "exact_match": false,
          "serial_latency_s": 0.6474,
          "concurrent_latency_s": 0.8332
        },
        {
          "index": 1,
          "prompt": "List three steps to verify an API endpoint is healthy.",
          "serial_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request (GET /health or similar endpoint)**  \n   Many APIs",
          "concurrent_output": "Here are three steps to verify an API endpoint is healthy:\n\n1. **Send a Health Check Request**  \n   Make a GET request (often to `/health",
          "token_agreement": 0.6667,
          "exact_match": false,
          "serial_latency_s": 0.7245,
          "concurrent_latency_s": 0.875
        },
        {
          "index": 2,
          "prompt": "What is the capital of France? Answer in one word.",
          "serial_output": "Paris",
          "concurrent_output": "Paris",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1365,
          "concurrent_latency_s": 0.2691
        },
        {
          "index": 3,
          "prompt": "Return exactly: ping",
          "serial_output": "ping",
          "concurrent_output": "ping",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1333,
          "concurrent_latency_s": 0.2272
        },
        {
          "index": 4,
          "prompt": "Name two risks of running without authentication.",
          "serial_output": "Running without authentication exposes systems and data to several security threats. Two major risks include:\n\n1. **Unauthorized Access**: Anyone with network or system access (including malicious",
          "concurrent_output": "Running without authentication poses significant security risks. Here are two major risks:\n\n1. **Unauthorized Access** \u2013 Anyone with access to the system or network can log in",
          "token_agreement": 0.1111,
          "exact_match": false,
          "serial_latency_s": 0.7099,
          "concurrent_latency_s": 0.876
        },
        {
          "index": 5,
          "prompt": "Summarize why deterministic decoding matters in testing.",
          "serial_output": "Deterministic decoding matters in testing because it ensures **predictable, repeatable, and reliable behavior** in systems that rely on decoding \u2014 such as neural networks,",
          "concurrent_output": "Deterministic decoding matters in testing because it ensures **predictable, consistent, and reproducible behavior** \u2014 which is essential for reliable validation and debugging. Here\u2019s",
          "token_agreement": 0.4583,
          "exact_match": false,
          "serial_latency_s": 0.7311,
          "concurrent_latency_s": 0.8757
        },
        {
          "index": 6,
          "prompt": "What does a 503 status code usually indicate?",
          "serial_output": "A **503 Service Unavailable** status code usually indicates that the server is **temporarily unable to handle the request**, often due to **overload",
          "concurrent_output": "A **503 Service Unavailable** status code usually indicates that the server is **temporarily unable to handle the request**, often due to:\n\n- **",
          "token_agreement": 0.8696,
          "exact_match": false,
          "serial_latency_s": 0.7171,
          "concurrent_latency_s": 0.8852
        },
        {
          "index": 7,
          "prompt": "Give a one-line definition of batch invariance.",
          "serial_output": "Batch invariance is the property of a model or algorithm whose output remains consistent regardless of the batch size used during training or inference.",
          "concurrent_output": "Batch invariance is the property of a model or system that produces consistent outputs regardless of the batch size used during inference or training.",
          "token_agreement": 0.7083,
          "exact_match": false,
          "serial_latency_s": 0.6392,
          "concurrent_latency_s": 0.8842
        },
        {
          "index": 8,
          "prompt": "Provide two bullet points on memory pressure guardrails.",
          "serial_output": "- Monitor and limit memory usage per container or process to prevent system-wide instability, using tools like cgroups or memory limits in orchestration platforms (e.g.,",
          "concurrent_output": "- Monitor and limit memory usage per container or pod to prevent resource contention and system instability, especially in multi-tenant environments.\n\n- Implement memory throttling and eviction",
          "token_agreement": 0.4074,
          "exact_match": false,
          "serial_latency_s": 0.7195,
          "concurrent_latency_s": 0.8285
        },
        {
          "index": 9,
          "prompt": "Output the word READY and nothing else.",
          "serial_output": "READY",
          "concurrent_output": "READY",
          "token_agreement": 1.0,
          "exact_match": true,
          "serial_latency_s": 0.1335,
          "concurrent_latency_s": 0.3361
        }
      ]
    }
  ],
  "timestamp_epoch": 1772065171
}